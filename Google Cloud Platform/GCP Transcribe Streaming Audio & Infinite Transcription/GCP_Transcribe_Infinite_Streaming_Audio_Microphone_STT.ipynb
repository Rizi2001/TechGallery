{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e589667-260a-4081-a4c3-43fa787b26ec",
   "metadata": {},
   "source": [
    "# Google Cloud's Speech API - Transcribe Infinitely Streaming Audio \n",
    "## https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio\n",
    "## https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/speech/microphone/transcribe_streaming_infinite.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a7a76-afa7-498d-b523-162a1c43add6",
   "metadata": {},
   "source": [
    "### This API can be used to transcribe streaming audio inifintely, providing real-time speech to text transcription via microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e213df1-5d05-4ee9-aad5-f82ebf2caf9e",
   "metadata": {},
   "source": [
    "#### The original documentation's implementation can only transcribe upto 305s ~ 5 minutes. This implementation allows to transcribe infinitely via microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66466a54-f19e-4d22-a34e-82781eb195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d79ea9-c939-4a1f-af71-3a9b21f97b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c251546-e450-4abe-b92e-047d1938cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bfa41-f1c9-4453-a628-eeb7696163e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "389d7193-a363-4244-83ea-b23b990fff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from google.cloud import speech\n",
    "\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a691ea64-122a-4c08-b451-4675524462ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\" #Replace with your GCP Project Credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09857ad5-68a0-4e05-9d2a-8623f1f597e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording parameters\n",
    "STREAMING_LIMIT = 240000  # 4 minutes\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "RED = \"\\033[0;31m\"\n",
    "GREEN = \"\\033[0;32m\"\n",
    "YELLOW = \"\\033[0;33m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "756e5da8-55a0-4af4-91da-9bad8b46b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time() -> int:\n",
    "    \"\"\"Return Current Time in MS.\n",
    "\n",
    "    Returns:\n",
    "        int: Current Time in MS.\n",
    "    \"\"\"\n",
    "\n",
    "    return int(round(time.time() * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cfbc9c7-72bc-440c-ae00-b2237a87469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumableMicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self: object,\n",
    "        rate: int,\n",
    "        chunk_size: int,\n",
    "    ) -> None:\n",
    "        \"\"\"Creates a resumable microphone stream.\n",
    "\n",
    "        Args:\n",
    "        self: The class instance.\n",
    "        rate: The audio file's sampling rate.\n",
    "        chunk_size: The audio file's chunk size.\n",
    "\n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.start_time = get_current_time()\n",
    "        self.restart_counter = 0\n",
    "        self.audio_input = []\n",
    "        self.last_audio_input = []\n",
    "        self.result_end_time = 0\n",
    "        self.is_final_end_time = 0\n",
    "        self.final_request_end_time = 0\n",
    "        self.bridging_offset = 0\n",
    "        self.last_transcript_was_final = False\n",
    "        self.new_stream = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def clear_transcription_history(self):\n",
    "        self.last_audio_input = []\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        \"\"\"Opens the stream.\n",
    "\n",
    "        Args:\n",
    "        self: The class instance.\n",
    "\n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Closes the stream and releases resources.\n",
    "\n",
    "        Args:\n",
    "        self: The class instance.\n",
    "        type: The exception type.\n",
    "        value: The exception value.\n",
    "        traceback: The exception traceback.\n",
    "\n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        *args: object,\n",
    "        **kwargs: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "        self: The class instance.\n",
    "        in_data: The audio data as a bytes object.\n",
    "        args: Additional arguments.\n",
    "        kwargs: Additional arguments.\n",
    "\n",
    "        returns: None\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Stream Audio from microphone to API and to local buffer\n",
    "\n",
    "        Args:\n",
    "            self: The class instance.\n",
    "\n",
    "        returns:\n",
    "            The data from the audio stream.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            data = []\n",
    "\n",
    "            if self.new_stream and self.last_audio_input:\n",
    "                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)\n",
    "\n",
    "                if chunk_time != 0:\n",
    "                    if self.bridging_offset < 0:\n",
    "                        self.bridging_offset = 0\n",
    "\n",
    "                    if self.bridging_offset > self.final_request_end_time:\n",
    "                        self.bridging_offset = self.final_request_end_time\n",
    "\n",
    "                    chunks_from_ms = round(\n",
    "                        (self.final_request_end_time - self.bridging_offset)\n",
    "                        / chunk_time\n",
    "                    )\n",
    "\n",
    "                    self.bridging_offset = round(\n",
    "                        (len(self.last_audio_input) - chunks_from_ms) * chunk_time\n",
    "                    )\n",
    "\n",
    "                    for i in range(chunks_from_ms, len(self.last_audio_input)):\n",
    "                        data.append(self.last_audio_input[i])\n",
    "\n",
    "                self.new_stream = False\n",
    "\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            self.audio_input.append(chunk)\n",
    "\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data.append(chunk)\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                    self.audio_input.append(chunk)\n",
    "\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd617db-821f-4c4c-aa9f-09c7c50a881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_print_loop(responses: object, stream: object) -> None:\n",
    "    for response in responses:\n",
    "        if get_current_time() - stream.start_time > STREAMING_LIMIT:\n",
    "            stream.start_time = get_current_time()\n",
    "            break\n",
    "\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        if result.is_final:\n",
    "            print(transcript)\n",
    "            stream.clear_transcription_history()\n",
    "\n",
    "        result_seconds = 0\n",
    "        result_micros = 0\n",
    "\n",
    "        if result.result_end_time.seconds:\n",
    "            result_seconds = result.result_end_time.seconds\n",
    "\n",
    "        if result.result_end_time.microseconds:\n",
    "            result_micros = result.result_end_time.microseconds\n",
    "\n",
    "        stream.result_end_time = int((result_seconds * 1000) + (result_micros / 1000))\n",
    "\n",
    "        corrected_time = (\n",
    "            stream.result_end_time\n",
    "            - stream.bridging_offset\n",
    "            + (STREAMING_LIMIT * stream.restart_counter)\n",
    "        )\n",
    "\n",
    "        if result.is_final:\n",
    "            sys.stdout.write(GREEN)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\n\")\n",
    "\n",
    "            stream.is_final_end_time = stream.result_end_time\n",
    "            stream.last_transcript_was_final = True\n",
    "\n",
    "            if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                sys.stdout.write(YELLOW)\n",
    "                sys.stdout.write(\"Exiting...\\n\")\n",
    "                stream.closed = True\n",
    "                break\n",
    "        else:\n",
    "            sys.stdout.write(RED)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\r\")\n",
    "\n",
    "            stream.last_transcript_was_final = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d726f66-4460-4dc1-a0fc-4aa1de2f1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"start bidirectional streaming from microphone input to speech API\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        language_code=\"en-US\",\n",
    "        max_alternatives=1,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)\n",
    "    print(mic_manager.chunk_size)\n",
    "    sys.stdout.write(YELLOW)\n",
    "    sys.stdout.write('\\nListening, say \"Quit\" or \"Exit\" to stop.\\n\\n')\n",
    "    sys.stdout.write(\"End (ms)       Transcript Results/Status\\n\")\n",
    "    sys.stdout.write(\"=====================================================\\n\")\n",
    "\n",
    "    with mic_manager as stream:\n",
    "        while not stream.closed:\n",
    "            sys.stdout.write(YELLOW)\n",
    "            sys.stdout.write(\n",
    "                \"\\n\" + str(STREAMING_LIMIT * stream.restart_counter) + \": NEW REQUEST\\n\"\n",
    "            )\n",
    "            stream.clear_transcription_history()\n",
    "            stream.audio_input = []\n",
    "            audio_generator = stream.generator()\n",
    "\n",
    "            requests = (\n",
    "                speech.StreamingRecognizeRequest(audio_content=content)\n",
    "                for content in audio_generator\n",
    "            )\n",
    "\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "            # Now, put the transcription responses to use.\n",
    "            listen_print_loop(responses, stream)\n",
    "\n",
    "            if stream.result_end_time > 0:\n",
    "                stream.final_request_end_time = stream.is_final_end_time\n",
    "            stream.result_end_time = 0\n",
    "            stream.last_audio_input = []\n",
    "            stream.last_audio_input = stream.audio_input\n",
    "            stream.audio_input = []\n",
    "            stream.restart_counter = stream.restart_counter + 1\n",
    "\n",
    "            if not stream.last_transcript_was_final:\n",
    "                sys.stdout.write(\"*\\n\")\n",
    "            stream.new_stream = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f9800b5-99c2-479f-b47d-803594d8d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "\u001b[0;33m\n",
      "Listening, say \"Quit\" or \"Exit\" to stop.\n",
      "\n",
      "End (ms)       Transcript Results/Status\n",
      "=====================================================\n",
      "\u001b[0;33m\n",
      "0: NEW REQUEST\n",
      "hello this is the infinitely transcribing Avitranscribing Avi\n",
      "\u001b[0;32m\u001b[K7930: hello this is the infinitely transcribing Avi\n",
      " API31m\u001b[K11320:  API\n",
      "\u001b[0;32m\u001b[K11950:  API\n",
      " videos of the Google Cloud console speech API and then there's some modification in there to control the station managementtation management\n",
      "\u001b[0;32m\u001b[K19910:  videos of the Google Cloud console speech API and then there's some modification in there to control the station management\n",
      " session managementession management\n",
      "\u001b[0;32m\u001b[K23950:  session management\n",
      " and in this raven able to transcribe any real time audio microphone infinitelyicrophone infinitely\n",
      "\u001b[0;32m\u001b[K34170:  and in this raven able to transcribe any real time audio microphone infinitely\n",
      " okay thank you butkay thank you bye\n",
      "\u001b[0;32m\u001b[K37830:  okay thank you but\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m responses \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mstreaming_recognize(streaming_config, requests)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Now, put the transcription responses to use.\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mlisten_print_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mresult_end_time \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     43\u001b[0m     stream\u001b[38;5;241m.\u001b[39mfinal_request_end_time \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mis_final_end_time\n",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m, in \u001b[0;36mlisten_print_loop\u001b[1;34m(responses, stream)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlisten_print_loop\u001b[39m(responses: \u001b[38;5;28mobject\u001b[39m, stream: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m get_current_time() \u001b[38;5;241m-\u001b[39m stream\u001b[38;5;241m.\u001b[39mstart_time \u001b[38;5;241m>\u001b[39m STREAMING_LIMIT:\n\u001b[0;32m      4\u001b[0m             stream\u001b[38;5;241m.\u001b[39mstart_time \u001b[38;5;241m=\u001b[39m get_current_time()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:115\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# If the stream has already returned data, we cannot recover here.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_channel.py:541\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_channel.py:958\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    956\u001b[0m     )\n\u001b[1;32m--> 958\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[1;32m--> 156\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[0;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[0;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[0;32m    115\u001b[0m ):\n\u001b[1;32m--> 116\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f78fc4-9dfd-477f-ad3c-27639e1b0dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa6f60-6d43-4ac4-9163-115b970b85b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
