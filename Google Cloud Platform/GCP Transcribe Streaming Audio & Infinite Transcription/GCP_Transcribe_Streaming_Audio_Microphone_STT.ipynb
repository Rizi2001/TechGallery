{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e589667-260a-4081-a4c3-43fa787b26ec",
   "metadata": {},
   "source": [
    "# Google Cloud's Speech API - Transcribe Streaming Audio \n",
    "## https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a7a76-afa7-498d-b523-162a1c43add6",
   "metadata": {},
   "source": [
    "#### This API can be used to transcribe streaming audio, providing real-time speech to text transcription via microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66466a54-f19e-4d22-a34e-82781eb195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d79ea9-c939-4a1f-af71-3a9b21f97b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c251546-e450-4abe-b92e-047d1938cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bfa41-f1c9-4453-a628-eeb7696163e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389d7193-a363-4244-83ea-b23b990fff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a691ea64-122a-4c08-b451-4675524462ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\" #Replace with your GCP Project Credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09857ad5-68a0-4e05-9d2a-8623f1f597e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording parameters\n",
    "RATE = 8000\n",
    "CHUNK = int(RATE / 10)  # 100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfbc9c7-72bc-440c-ae00-b2237a87469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self: object, rate: int = RATE, chunk: int = CHUNK) -> None:\n",
    "        \"\"\"The audio -- and generator -- is guaranteed to be on the main thread.\"\"\"\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> None:\n",
    "        \"\"\"Closes the stream, regardless of whether the connection was lost or not.\"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        frame_count: int,\n",
    "        time_info: object,\n",
    "        status_flags: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "            in_data: The audio data as a bytes object\n",
    "            frame_count: The number of frames captured\n",
    "            time_info: The time information\n",
    "            status_flags: The status flags\n",
    "\n",
    "        Returns:\n",
    "            The audio data as a bytes object\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Generates audio chunks from the stream of audio data in chunks.\n",
    "\n",
    "        Args:\n",
    "            self: The MicrophoneStream object\n",
    "\n",
    "        Returns:\n",
    "            A generator that outputs audio chunks.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd617db-821f-4c4c-aa9f-09c7c50a881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_print_loop(responses: object) -> str:\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "\n",
    "    Args:\n",
    "        responses: List of server responses\n",
    "\n",
    "    Returns:\n",
    "        The transcribed text.\n",
    "    \"\"\"\n",
    "    num_chars_printed = 0\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # The `results` list is consecutive. For streaming, we only care about\n",
    "        # the first result being considered, since once it's `is_final`, it\n",
    "        # moves on to considering the next utterance.\n",
    "        # result = response.results[0]\n",
    "        # if not result.alternatives:\n",
    "        #     continue\n",
    "        \n",
    "        result = response.results[0]\n",
    "        # print(result)\n",
    "        transcript = result.alternatives[0].transcript\n",
    "        # print(transcript, result.is_final)\n",
    "        # continue\n",
    "        if(result.is_final == True):\n",
    "                \n",
    "            print(transcript)\n",
    "        continue\n",
    "\n",
    "        \n",
    "        # Display the transcription of the top alternative.\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "        #\n",
    "        # If the previous result was longer than this one, we need to print\n",
    "        # some extra spaces to overwrite the previous result\n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                print(\"Exiting..\")\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0\n",
    "\n",
    "        return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d726f66-4460-4dc1-a0fc-4aa1de2f1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Transcribe speech from audio file.\"\"\"\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = \"en-US\"  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Now, put the transcription responses to use.\n",
    "        listen_print_loop(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9800b5-99c2-479f-b47d-803594d8d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you this is to test the Google Cloud speech a bi transcribing streaming audio\n",
      " API\n",
      " so this APO works for a convicted 305 seconds that is roughly around 5 minutes and then decision brakes\n",
      " consecutive 305 seconds\n",
      " and then the session ends\n",
      " so below this implementation there's an implementation for infinite streaming audio transcription\n",
      " which would automatically generates a session after 305 seconds\n",
      " okay thank you bye\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m responses \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mstreaming_recognize(streaming_config, requests)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Now, put the transcription responses to use.\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mlisten_print_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36mlisten_print_loop\u001b[1;34m(responses)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates through server responses and prints them.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mThe responses passed is a generator that will block until a response\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    The transcribed text.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m num_chars_printed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresults:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:115\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# If the stream has already returned data, we cannot recover here.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_channel.py:541\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_channel.py:958\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    956\u001b[0m     )\n\u001b[1;32m--> 958\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[1;32m--> 156\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\site-packages\\grpc\\_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[0;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[0;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[0;32m    115\u001b[0m ):\n\u001b[1;32m--> 116\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\speech_env\\lib\\threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f78fc4-9dfd-477f-ad3c-27639e1b0dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d2f0980-fb23-45af-8f9e-4a85f1676350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.083333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "305/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa6f60-6d43-4ac4-9163-115b970b85b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
