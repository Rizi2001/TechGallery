{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1dd256c-52df-498d-826e-c70b33c946f5",
   "metadata": {},
   "source": [
    "# Chat Bot using Text Embeddings and comparing similarity with Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56422d-c08f-4bc0-be79-b98b2a607042",
   "metadata": {},
   "source": [
    "## Google Text Embedding Model: textembedding-gecko@001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7b997f-2b26-46f5-a86f-b9ac4c9437e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = ''#Path to your Google Cloud's Service Account Crediatials JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae362dd-bc43-4f4a-b26c-57bae6c2d611",
   "metadata": {},
   "source": [
    "# Generating Base Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c79b7e-a645-4fa4-ae57-a035085de668",
   "metadata": {},
   "source": [
    "### Base Embeddings for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85ce04-bdb8-49d7-b6b0-971d4183c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a1105-a24b-49ff-b156-bba423dbd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(data, batch_size=5):\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "    \n",
    "    questions = data[\"Processed Questions\"].tolist()\n",
    "    \n",
    "    embedding_vectors = []\n",
    "\n",
    "    question_list = []\n",
    "\n",
    "    for i in range(0, len(questions), batch_size):\n",
    "        batch = questions[i:i + batch_size]\n",
    "\n",
    "        embeddings = model.get_embeddings(batch)\n",
    "        \n",
    "        for question, embedding in zip(batch, embeddings):\n",
    "            vector = embedding.values\n",
    "            embedding_vectors.append(vector)\n",
    "            question_list.append(question)\n",
    "    \n",
    "    embedding_df = pd.DataFrame({\"Question\": question_list, \"Embedding\": embedding_vectors})\n",
    "    \n",
    "    embedding_df.to_csv(\"embeddings.csv\", index=False)\n",
    "    \n",
    "    return embedding_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe937ca0-d687-4a5d-9bf3-02e8b601adf6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645944f9-3976-4d1a-a529-e20661580bb0",
   "metadata": {},
   "source": [
    "### Pytorch's Cosine Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95136ec1-6fd3-4497-b9c8-45306723ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87835b05-f08c-4b44-9e3e-6c68c5ffb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV file containing question embeddings and answers\n",
    "embedding_df = pd.read_csv(\"embeddings.csv\")\n",
    "embedding_df['Embedding'] = embedding_df['Embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7863a76-db5a-444b-9325-4f48bd8ab2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4b8c1-d725-491e-bf2d-ef51440fd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88728595-c789-497c-94fe-9f23de4d463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ef8c8-b974-405d-a8db-e27230ed1dae",
   "metadata": {},
   "source": [
    "### Preprocessing Data using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c84a6-a1e1-461b-a493-066f5146f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_punct])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340503d3-0269-4014-bb60-4464cbaa7d64",
   "metadata": {},
   "source": [
    "### Returns the predicted answer by first calculating the maximum cosine similarity with the Base Embeddings previously generated, calculating the index with which the similarity score was the maximum, returning the answer on that index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd1462-a9f7-4730-814e-a7c7542e7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_question(user_question, question_embeddings_df):\n",
    "    user_question = preprocess_text(user_question)\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "    user_question_embedding = model.get_embeddings([user_question])\n",
    "    for embedding in user_question_embedding:\n",
    "        user_question_embedding = embedding.values\n",
    "    \n",
    "    question_embeddings = question_embeddings_df['Embedding']\n",
    "    sim_score = []\n",
    "    for i in question_embeddings:\n",
    "        sim_score.append(util.pytorch_cos_sim(user_question_embedding, i).item())\n",
    "\n",
    "    sim_arg = sim_score.index(max(sim_score))\n",
    "    return embedding_df['Answer'][sim_arg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc87249-f827-4e6c-9303-de8c99f0cdae",
   "metadata": {},
   "source": [
    "### Evaluation Function to test the Chat Bot with providing the test questions with ground truth answers in the format 'test_dataset' variable is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020ad7e-4d45-45e1-89b0-1ab35a16b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_chatbot(test_dataset, embedding_df):\n",
    "    correct_answers = 0\n",
    "    total_questions = len(test_dataset)\n",
    "\n",
    "    \n",
    "    for test_question, ground_truth_answer in test_dataset:\n",
    "        start_time = time.time()\n",
    "    \n",
    "        response = get_most_similar_question(test_question, embedding_df)\n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"Time taken: {end_time - start_time}\\n\")\n",
    "        \n",
    "        if response == ground_truth_answer:\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            print(\"\\nWrong Answer\\n\")\n",
    "        \n",
    "        print(f\"\\n\\nQuestion: {test_question}\\n\")\n",
    "        print(f\"Chatbot's Response: {response}\\n\")\n",
    "        print(f\"Ground Truth Answer: {ground_truth_answer}\\n\")\n",
    "    \n",
    "    accuracy = (correct_answers / total_questions) * 100\n",
    "    return accuracy\n",
    "\n",
    "test_dataset = [\n",
    "    (\"Question1\",\"Answer1\"),\n",
    "    (\"Question2\", \"Answer2\")\n",
    "]\n",
    "\n",
    "\n",
    "accuracy = evaluate_chatbot(test_dataset, embedding_df)\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0d04f-3de7-4487-9387-780af32769fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
