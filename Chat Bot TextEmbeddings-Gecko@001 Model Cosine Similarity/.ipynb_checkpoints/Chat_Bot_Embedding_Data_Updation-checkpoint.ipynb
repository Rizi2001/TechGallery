{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32679e17-eb9f-4ee6-a080-e40f986c9736",
   "metadata": {},
   "source": [
    "# Embedding Data Updation for the Text-Embedding based Chat Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f912d978-3813-4e0d-9f36-1aea0cf50dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 17:05:27.766983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-24 17:05:29.333725: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "import spacy\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sentence_transformers import util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "# from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639945d8-005a-4785-a5fe-009626f84073",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\" # Replace with OPENAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722986ac-7405-45e1-a84b-48d08b8fad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] =  \"\" # Replace with GCP Credentials JSON File Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738045e9-6b34-4669-8ef5-e1a3d89832d9",
   "metadata": {},
   "source": [
    "## Generate Testing Variations from Question/Answer CSV using OPENAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb817ba5-1cb8-4a1e-9748-c93651f9c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variations_openai(prompt):\n",
    "    full_prompt = f\"Generate a 'single' unique variation for the question below and return another single question without changing the semantics and the meaning, only the wording should be different: \\\"{prompt}\\\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=full_prompt,\n",
    "    temperature=0.1\n",
    "    )\n",
    "\n",
    "    output = list()\n",
    "    for k in response['choices']:\n",
    "        output.append(k['text'].strip())\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee9d65-ade4-48a5-8112-323bd9fe1e37",
   "metadata": {},
   "source": [
    "## Generate Testing Variations from Question/Answer CSV using GCP Vertex AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e20044d-1035-4172-aeb1-5a9fe7d8cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variations_vertex(prompt): \n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    \n",
    "    full_prompt = f\"Generate a 'single' unique variation for the question below and return another single question without changing the semantics and the meaning, only the wording should be different: \\\"{prompt}\\\"\"\n",
    "    \n",
    "    response = model.predict(prompt=full_prompt, temperature=0.4)\n",
    "\n",
    "    return (response.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9f38a-8408-4dd4-9ab0-796602d351dc",
   "metadata": {},
   "source": [
    "## New questions CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3916f2eb-c3e2-4f2b-904b-cbb682aeaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question_data_file = 'Chat_Bot_New_Questions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275922f2-80af-4849-9611-449242a70f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(new_question_data_file, encoding='utf-8')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f98da6-b029-4391-8344-b72ed976281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7c0d1-614a-4464-bfba-412dc5cd4986",
   "metadata": {},
   "source": [
    "## Generating a variation for each new question from a language model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4152c65-e116-42db-ba44-ef7bc6b4292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "answer_list = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    response = generate_variations_openai(df['Question'][i])\n",
    "    print(i)\n",
    "\n",
    "    print(f\"{i}: {response}\")\n",
    "    # print(df['Question'][i].strip())\n",
    "\n",
    "    response_list.append(df['Question'][i])\n",
    "    response_list.append(response)\n",
    "    answer_list.append(df['Answer'][i])\n",
    "    answer_list.append(df['Answer'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8391dace-0beb-42dc-90df-17db2139fe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Question': response_list, 'Answer': answer_list})\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa355c-3d99-4ae2-b68c-9c6824de1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521cfb17-2878-4ef7-9066-011c7dd616c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534c13b-d747-48f9-a7ab-0d3263689599",
   "metadata": {},
   "source": [
    "## Text Embedding for the newly added and generated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91606e2f-fecc-42a7-bc6d-c611e7964690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(data, batch_size=5):\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "    \n",
    "    questions = data[\"Question\"].tolist()\n",
    "    \n",
    "    embedding_vectors = []\n",
    "\n",
    "    question_list = []\n",
    "\n",
    "    for i in range(0, len(questions), batch_size):\n",
    "        print(i)\n",
    "        batch = questions[i:i + batch_size]\n",
    "\n",
    "        embeddings = model.get_embeddings(batch)\n",
    "        \n",
    "        for question, embedding in zip(batch, embeddings):\n",
    "            vector = embedding.values\n",
    "            embedding_vectors.append(vector)\n",
    "    \n",
    "    return embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1383c78e-eb4a-4cfd-9a31-dcff68250cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vec = text_embedding(df)\n",
    "len(emb_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a20705-c899-425e-b983-c924db594b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embedding'] = emb_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04509bc3-ef7b-4d1f-b95c-e73e33b26c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c8bad-ad56-46d0-bfa8-ca31dfbfd67f",
   "metadata": {},
   "source": [
    "## Previous Question / Answer Embedding Data (To be updated yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95fa9dfa-3b1a-4d59-8285-c61446c33601",
   "metadata": {},
   "outputs": [],
   "source": [
    "Old_question_data_file = \"Question_Variations_Embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8f5f9-c43e-4e55-b51d-988e1ba15ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.read_csv(Old_question_data_file)\n",
    "embedding_df['Embedding'] = embedding_df['Embedding'].apply(ast.literal_eval)\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccaa1dd-50ba-442f-90ad-921f737b8ea2",
   "metadata": {},
   "source": [
    "## Concatinating the new dataframe to the previous dataframe to update the whole Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0c74e-baec-4f2d-8a4d-264a691d04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([embedding_df, df])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75744646-22ee-42da-adfa-d08e2df56fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b435d9-d100-4285-a6a0-9b89ec686410",
   "metadata": {},
   "source": [
    "## Saving the updated dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dee9c19-2223-4a16-b6b3-3a082373df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Question_Variations_Embeddings_Updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be03ac-9796-4c88-a19b-60af2d47d026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8129645-c5dc-4c0a-ac24-9dffdbfea8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
